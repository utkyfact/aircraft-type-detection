{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Military Aircraft Image Classification Using Custom Dataset Project\n",
    "\n",
    "In this project we will use Transfer Learning for Image Classification. But unlike previous projects:\n",
    "1. We will use our own custom dataset in this project for both training and testing\n",
    "2. We will use VGG16 pre-trained complex deep learning model\n",
    "\n",
    "Airplane images from MTARSI (Muti-type Aircraft of Remote Sensing Images, https://zenodo.org/record/3464319#.YUiSrrgzaUk) were used as dataset, but the dataset size reduced and images were rearranged for training purposes. The images of MTARSI are generally remote sensing images acquired from satellite imagery available in the Internet. \n",
    "\n",
    "You can download the customized Aircraft Images from UDEMY \"Project Source Codes\" section of this lecture.\n",
    "\n",
    "<IMG src=\"b52.png\" width=\"200\" height=\"200\">\n",
    "<IMG src=\"a10.jpg\" width=\"200\" height=\"200\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img # For image operations\n",
    "from tensorflow.keras.models import Sequential # These are required for building our new model\n",
    "from tensorflow.keras.layers import Dense # These are required for building our new model\n",
    "from tensorflow.keras.applications.vgg16 import VGG16  # The Transfer Learning model to be used in this project...\n",
    "from tensorflow.keras.applications.vgg16 import preprocess_input, decode_predictions\n",
    "from PIL import Image # Python Imaging Library - For operations like: Image open, resize image, etc..\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will define our train and test image paths...\n",
    "train_files_path = \"airplanedataset/Train/\"\n",
    "test_files_path = \"airplanedataset/Test/\"\n",
    "\n",
    "# Let's load any airplane image from our dataset..\n",
    "img = load_img(test_files_path + \"B-52/3-1.jpg\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# What is the size?\n",
    "print(img_to_array(img).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see this airplane, check if we can see it correctly?\n",
    "plt.imshow(img)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Everyting Ok. Now we should build our test and train datasets from the directories of airplane images..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build our train and test datasets from the directories of airplane images..\n",
    "train_data = ImageDataGenerator().flow_from_directory(train_files_path,target_size = (224,224))\n",
    "test_data = ImageDataGenerator().flow_from_directory(test_files_path,target_size = (224,224))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "numberOfAirplaneTypes = 5  # If you have added other planes types (with airplane images in directories of course)\n",
    "                           # then you must change this number...\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building the Model \n",
    "\n",
    "We will use Transfer Learning, specially VGG16 model for our project!..\n",
    "Bur VGG16 model has its own inputs both for training and test, therefore we should change the inputs..\n",
    "\n",
    "Original VGG16 model is designed for ImageNet dataset (which is a dataset of over 15 million labeled high-resolution images belonging to roughly 22,000 categories) which has 1000 image categories which are not specifically aircraft images. \n",
    "This means we will build a new model for classificiation of aircraft images in our dataset and use VGG16 pre-trained layers in this new model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's build our model object..\n",
    "vgg = VGG16()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg_layers = vgg.layers\n",
    "print(vgg_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I'm gonna build a new Sequential model and I will add the all the layers from the Vgg16 model to my new model except \n",
    "# the last layer which is the output layer! Because I will build my own output layer according to my \n",
    "# input classes (which are the types of my military aircrafts)... \n",
    "# For this I define vggmodel_layersize_tobe_used = len(vgg_layers) - 1 (minus 1 means I omit the last layer - the output layer)\n",
    "vggmodel_layersize_tobe_used = len(vgg_layers) - 1\n",
    "\n",
    "model = Sequential()\n",
    "for i in range(vggmodel_layersize_tobe_used):\n",
    "    model.add(vgg_layers[i])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since I don't want to re-train all the original 16 layers of VGG16\n",
    "# which has about 138 million (approx) parameters. VGG model has good train parameters, I will use them!!\n",
    "for layers in model.layers:\n",
    "    layers.trainable = False\n",
    "\n",
    "# Since I have omitted the original output layer of VGG16, I have to add my new output layer to my new model!\n",
    "model.add(Dense(numberOfAirplaneTypes, activation=\"softmax\"))\n",
    "\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After model design is complete, it's time to compile...\n",
    "model.compile(loss = \"categorical_crossentropy\",\n",
    "              optimizer = \"rmsprop\",\n",
    "              metrics = [\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "batch_size = 4 \n",
    "\n",
    "model.fit_generator(train_data,\n",
    "                           steps_per_epoch=400//batch_size,\n",
    "                           epochs= 3, # You can increase epoch size if you have a computer with good specs...\n",
    "                           validation_data=test_data,\n",
    "                           validation_steps= 200//batch_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " #### Please remember accuracy is the accuracy of a batch of training data and val_accuracy is the accuracy of a batch of testing data.. So we have a good 87% validation accuracy of our model with test dataset (the images our model has not seen before)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have good accuracy.. Now it's time to test our new Military Aircraft Recognition model with own eyes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load an aircraft image and rescale it to the resolution of 224x224 which VGG16 requires..\n",
    "img = Image.open(\"f22.jpg\").resize((224,224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We must convert it to array for operations...\n",
    "img = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look it's shape..\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to add an extra dimension to our array so we will reshape it.. \n",
    "img = img.reshape(-1,224,224,3)   # with reshape(-1,..) I'm adding 1 extra dimension..\n",
    "                                  # I do this because my model requires 4 dim array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look it's shape..\n",
    "print(img.shape)\n",
    "print(img.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will scale input pixels between -1 and 1 using my model's preprocess_input\n",
    "# VGG16 model requires it..\n",
    "img = preprocess_input(img)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see the aircraft..\n",
    "img_for_display = load_img(\"f22.jpg\")\n",
    "plt.imshow(img_for_display)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let's make a prediction..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = model.predict(img)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's see contents of prediction array.. \n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These are the possibilities of each output (one-hot encoding)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please remember the concept of Softmax:\n",
    "\n",
    "For example, three class labels will be integer encoded as 0, 1, and 2. Then encoded to vectors as follows:\n",
    "\n",
    "Class 0: [1, 0, 0]\n",
    "Class 1: [0, 1, 0]\n",
    "Class 2: [0, 0, 1]\n",
    "This is called a one-hot encoding.\n",
    "\n",
    "In our case:\n",
    "A-10  Thunderbolt: [1,0,0,0,0]\n",
    "Boeing B-52: [0,1,0,0,0]\n",
    ".... \n",
    "like this..\n",
    "\n",
    "For example, if the integer encoded class 1 was expected for example, the target vector would be:\n",
    "[0, 1, 0]\n",
    "\n",
    "The softmax output might look as follows, which puts the most weight on class 1 and less weight on the other classes.\n",
    "\n",
    "For example in 3 output example above if we would have a softmax output like this: \n",
    "[0.09003057 0.67524096 0.23472847]\n",
    "\n",
    "Then we can say the highest probability outcome is  0.67524096 which is Class 1.\n",
    "I can find the index simply using numpy's argmax funxtion:\n",
    "\n",
    "class integer = argmax([0.09003057 0.67524096 0.23472847])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_classes = [\"A-10 Thunderbolt\",\"Boeing B-52\",\"Boeing E-3 Sentry\",\"F-22 Raptor\",\"KC-10 Extender\"]\n",
    "\n",
    "result = np.argmax(preds[0])\n",
    "print(image_classes[result]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
