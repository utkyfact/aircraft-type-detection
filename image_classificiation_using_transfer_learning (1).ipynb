{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Image Classification using Transfer Learning\n",
    "\n",
    "In this project we will make image classification using Transfer Learning. For this purpose we will use the InceptionResNetV2 model which is trained on the imageNet data set. Lets use a submarine image for classification. I found this image in Internet, this image is not included in imageNet dataset which was used for training InceptionResNetV2.\n",
    "\n",
    "In transfer learning we use a model that has been previously trained on a dataset and contains the weights and biases that represent the features of whichever dataset it was trained on. \n",
    "\n",
    "Inception and ResNet have been among the best image recognition performance models in recent years, with very good performance at a relatively low computational cost. Inception and ResNet combines the Inception architecture, with residual connections."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from PIL import Image # Python Imaging Library - For operations like: Image open, resize image, etc..\n",
    "from IPython.display import Image as show_image  # For displaying our test images to you\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "from tensorflow.keras.preprocessing import image\n",
    "from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input, decode_predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The InceptionResNetV2 pre-trained model expects inputs of 299x299 resolution.  \n",
    "##### InceptionResNetV2 model will classify images into one of 1,000 possible categories.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's load our image and rescale it to the resolution of 299x299 which InceptionResNetV2 requires..\n",
    "img = Image.open(\"submarine.jpg\").resize((299,299))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We must convert it to array for operations...\n",
    "img = np.array(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look it's shape..\n",
    "img.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have to add an extra dimension to our array so we will reshape it.. \n",
    "img = img.reshape(-1,299,299,3)   # with reshape(-1,..) I'm adding 1 extra dimension..\n",
    "                                  # I do this because my model requires 4 dim array!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's look it's shape..\n",
    "img.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(img.ndim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I will scale input pixels between -1 and 1 using my model's preprocess_input\n",
    "# InceptionResNetV2 model requires it..\n",
    "img = preprocess_input(img)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load up the model itself:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "incresv2_model = InceptionResNetV2(weights='imagenet', classes=1000)   # InceptionResNetV2 will classify images into one of \n",
    "                                                                       # 1,000 possible categories."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lets inspect InceptionResNetV2 model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now look at it's layers:\n",
    "print(incresv2_model.summary())\n",
    "print(type(incresv2_model))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before prediction let's see our image with our eyes first:\n",
    "show_image(filename='submarine.jpg') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's already trained with weights learned from the Imagenet data set. Now we will use it by calling incresv2_model's predict() method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = incresv2_model.predict(img)\n",
    "print('Predicted categories:', decode_predictions(preds, top=2)[0]) # decode the results into a list of tuples "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lets make another prediction.. I downloaded all these images from the web. These images are not in ImageNet. you can try yourself, download any image from the web and make a prediction using the model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "arr = np.arange(24)\n",
    "\n",
    "print(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above array arr has only 1 dimension. It is the simplest array since it has the min possible dimension size:1.."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Increasing the dimension size of a numpy array using reshape(-1,..)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr = arr.reshape(-1,24) #We added an extra dimension to array a with reshape(-1,24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr.ndim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see above we have increased the dimension of our array arr. Now it is 2 dimensional... Original values have become the first row now!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
